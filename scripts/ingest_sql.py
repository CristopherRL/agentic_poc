from __future__ import annotations
import json
import logging
import sqlite3
import time
from pathlib import Path
import pandas as pd
from sqlalchemy import create_engine
from src.app.config import settings

LOGGER = logging.getLogger(__name__)


def load_csvs(csv_dir: Path) -> dict[str, pd.DataFrame]:
    frames: dict[str, pd.DataFrame] = {}
    for csv_file in sorted(csv_dir.glob("*.csv")):
        table_name = csv_file.stem.upper()
        LOGGER.info("Loading %s into table %s", csv_file.name, table_name)
        frames[table_name] = pd.read_csv(csv_file)
    if not frames:
        raise FileNotFoundError(f"No CSV files found in {csv_dir}")
    return frames


def persist_frames(frames: dict[str, pd.DataFrame], db_path: Path) -> None:
    db_path.parent.mkdir(parents=True, exist_ok=True)
    engine = create_engine(f"sqlite:///{db_path}")
    try:
        for table_name, frame in frames.items():
            LOGGER.info("Writing table %s (%d rows)", table_name, len(frame))
            frame.to_sql(table_name, engine, if_exists="replace", index=False)
    finally:
        engine.dispose()


def write_schema_report(frames: dict[str, pd.DataFrame], db_path: Path, report_path: Path) -> None:
    report_path.parent.mkdir(parents=True, exist_ok=True)
    connection = sqlite3.connect(db_path)
    try:
        cursor = connection.cursor()
        cursor.execute("SELECT name, sql FROM sqlite_master WHERE type='table' ORDER BY name")
        tables = cursor.fetchall()
    finally:
        connection.close()

    lines: list[str] = ["# SQLite Schema Overview", "", "Generated by scripts/ingest_sql.py", ""]
    for table_name, create_sql in tables:
        lines.append(f"## Table: {table_name}")
        lines.append("")
        if create_sql:
            lines.append("```sql")
            lines.append(create_sql)
            lines.append("```")
            lines.append("")

        comment = settings.table_comments.get(table_name.upper())
        if comment:
            lines.append(comment)
            lines.append("")

        frame = frames.get(table_name.upper())
        if frame is not None:
            sample = frame.head(2).to_dict(orient="records")
            lines.append("Sample rows:")
            lines.append("```json")
            lines.append(json.dumps(sample, ensure_ascii=False, indent=2))
            lines.append("```")
            lines.append("")

    report_path.write_text("\n".join(lines), encoding="utf-8")
    LOGGER.info("Schema report written to %s", report_path)


def reset_database(db_path: Path | None = None) -> None:
    target = db_path or settings.sqlite_path
    if not target.exists():
        return

    for attempt in range(3):
        try:
            target.unlink()
            LOGGER.info("Removed existing database at %s", target)
            return
        except PermissionError:
            time.sleep(0.3)

    LOGGER.warning("Could not delete %s; attempting to drop existing tables", target)
    connection = sqlite3.connect(target)
    try:
        cursor = connection.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        for (table_name,) in cursor.fetchall():
            cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
            LOGGER.info("Dropped table %s", table_name)
        connection.commit()
    finally:
        connection.close()


def ingest(csv_dir: Path | None = None, db_path: Path | None = None, schema_path: Path | None = None) -> None:
    source_dir = csv_dir or settings.csv_dir
    target_db = db_path or settings.sqlite_path
    report_path = schema_path or settings.sql_schema_path

    reset_database(target_db)

    frames = load_csvs(source_dir)
    persist_frames(frames, target_db)
    write_schema_report(frames, target_db, report_path)
    LOGGER.info("SQLite database written to %s", target_db)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(levelname)s %(message)s")
    ingest()
